# [2. 词法分析](https://docs.python.org/3/reference/lexical_analysis.html)

Python程序由*解析器*读取。输入到解析器中的是由*词法分析器*生成的标记流。本章描述词法分析器如何把一个文件拆分成标记。

Python将程序文本作为Unicode码点读取；源文件的编码由编码声明给出，默认值为UTF-8，详细信息参考[**PEP 3120**](https://www.python.org/dev/peps/pep-3120/)。如果源文件不能被解码，将引发[SyntaxError](https://docs.python.org/3/library/exceptions.html#SyntaxError)异常。

## [2.1. 行结构](https://docs.python.org/3/reference/lexical_analysis.html#line-structure)

Python程序被拆分为多个*逻辑行*。

### [2.1.1. 逻辑行](https://docs.python.org/3/reference/lexical_analysis.html#logical-lines)

逻辑行的结束由 NEWLINE 标记表示。除非语法允许 NEWLINE（e.g. 复合语句的语句之间），否则语句不能跨越逻辑行的边界。逻辑行由一个或多个*物理行*构建，并遵循显式或隐式*行连接*规则。

### [2.1.2. 物理行](https://docs.python.org/3/reference/lexical_analysis.html#physical-lines)

物理行是一个 end-of-line 序列终止的字符序列。在源文件中，可以使用任何标准平台的行终止序列——Unix形式使用 ASCII 的 LF（换行），windows形式使用 ASCII 序列 CR LF（回车，换行），或者Macintosh过去使用的 ACSII 的 CR（回车）字符。

在嵌入Python时，对于换行符源代码字符串，应该使用标准C的习惯传递给 Python API（`\n`字符，相当于 ASCII LF，作为行终止符）。

### [2.1.3. 注释](https://docs.python.org/3/reference/lexical_analysis.html#comments)

注释以井号`#`开头，以该物理行结束处中止。（注释字符串并不包含`#`)。注释表示逻辑行的结尾，除非调用隐式行连接。语法忽略注释；注释不是标记。

### [2.1.4. 编码声明](https://docs.python.org/3/reference/lexical_analysis.html#encoding-declarations)

如果Python脚本的第一行或第二行注释匹配正则表达式`coding[=:]\s*([-\w.]+)`，该注释将作为编码声明处理；该表达式的第一个分组给出了该源文件的编码。编码声明必须出现在自己的一行上。如果它处于第二行，第一行也必须为纯注释行。编码声明的推荐格式为

```python
# -*- coding: <编码名> -*-
```

这是被GNU Emacs认可的，以及

```python
# vim:fileencoding=<编码名>
```

这是被Bram Moolenaar 的 VIM认可的。

如果没有找到编码声明，将被默认声明为 UTF-8。此外，如果该文件开始的几个字节是UTF-8的字节顺序标记（`b'\xef\xbb\xbf'`）。该编码声明为 UTF-8。（这个特性也被微软的**notepad**和其它编辑器支持。）

如果编码被声明，该编码必须能被Python识别。该编码被用于所有的词法分析，包括字符串字面值，注释和标识符。

### [2.1.5. 显式行连接](https://docs.python.org/3/reference/lexical_analysis.html#explicit-line-joining)

两条或更多的物理行可以使用反斜杠（\）连接为逻辑行。如下：当一个物理行以反斜杠结尾并且它不处于字符串字面量或注释中，它将连接之后的至同一逻辑行，并删去反斜杠以及行尾字符。例：

```python
if 1900 < year < 2100 and 1 <= month <= 12 \
   and 1 <= day <= 31 and 0 <= hour < 24 \
   and 0 <= minute < 60 and 0 <= second < 60:   # 看起来是一个合法日期
        return 1
```

以反斜杠结尾的行不能包含注释。反斜杠不会继续注释。除了字符串面面值（即，除了字符串面值之外的标记不能使用反斜杠在物理行上分割）之外，反斜杠不继续标记。反斜杠在字符串外面的行上是非法的。A backslash is illegal elsewhere on a line outside a string literal.

### [2.1.6. 隐式行连接](https://docs.python.org/3/reference/lexical_analysis.html#implicit-line-joining)

圆括号，方括号或花括号中的表达式可以在不使用反斜杠的情况下在多个物理行上分割。例如：

```python
month_names = ['Januari', 'Februari', 'Maart',      # 这些是荷兰语
               'April',   'Mei',      'Juni',       # 中的12个月份
               'Juli',    'Augustus', 'September',
               'Oktober', 'November', 'December']
```

隐式行连接可以带有注释。连续行的缩进并不重要。允许空白连续行。隐式连续行之间没有NEWLINE标记。隐式连续的行，也可能发生在三引号字符串 （见下文）；在这种情况下他们不能带有注释。

### [2.1.7. 空白行](https://docs.python.org/3/reference/lexical_analysis.html#blank-lines)

忽略只包含空格，制表符，换行符和注释的逻辑行（即不生成NEWLINE词符号）。在语句的交互式输入期间，空白行的处理可以根据read-eval-print循环的实现而不同。在标准的交互式解释器，完全空白的逻辑行 （即既不含空格也不包含注释） 终止多行语句。

### [2.1.8. 缩进](https://docs.python.org/3/reference/lexical_analysis.html#indentation)

逻辑行开头处的前导空格（空格和制表符）用于计算行的缩进级别，而后者又用于确定语句的分组。

制表符（从左到右）被替换一到八个空格，使得替换的字符总数是8的倍数（这与Unix使用相同的规则）。然后，第一个非空白字符前面的空格总数确定行的缩进。缩进不可以使用反斜杠分割成多个物理行；直到第一个反斜杠处的空白决定了缩进。

如果源文件混合使用制表符和空格，使得其意义依赖于制表符换算成空格的数目，则缩进会被认为不一致而拒绝；这种情形将引发一个[TabError](https://docs.python.org/3/library/exceptions.html#TabError)。

**跨平台兼容性说明：** 由于非UNIX平台上的文本编辑器的性质，在单个源文件中缩进的空格和制表符混合使用是不明智的。还应当注意，不同的平台可能限制最大缩进级别。

在行的起始处，可能存在一个换页符字符；它将忽略上面的缩进计算。在前导空白字符的其他位置出现的换行字符具有未定义的效果（比如，它们可能将空格计数重置为零）。

连续行的缩进级别用于生成INDENT和DEDENT词符，使用堆栈，如下所示。

读取该文件的第一行之前，单独的一个零被压入堆栈；这将不会再次被弹出。在堆栈上推送的数字将总是从底部到顶部严格增加。在每个逻辑行的开始，将行的缩进级别与堆栈的顶部进行比较。如果相等，什么也没有发生。如果它更大，它被推到堆栈，并生成一个INDENT标记。如果它是更小的，它*必须*是在堆栈中的一个数字。在堆栈上所有较大的数字弹出时，并且为每个弹出的数字生成DEDENT标记。在文件的末尾，对于堆栈上剩余的每个大于零的数字，生成DEDENT标记。

这是一个正确缩进的Python代码片段的例子（虽然混乱）：

```python
def perm(l):
        # 计算并返回l所有排列的列表
    if len(l) <= 1:
                  return [l]
    r = []
    for i in range(len(l)):
             s = l[:i] + l[i+1:]
             p = perm(s)
             for x in p:
              r.append(l[i:i+1] + x)
    return r
```

以下示例展示各种缩进错误：

```python
 def perm(l):                       # 错误：第一行缩进
for i in range(len(l)):             # 错误：没有缩进
    s = l[:i] + l[i+1:]
        p = perm(l[:i] + l[i+1:])   # 错误：错误缩进
        for x in p:
                r.append(l[i:i+1] + x)
            return r                # 错误：缩进不一致
```

（事实上，前三个错误是由解析器发现的；仅最后一个错误是由词法分析器找到的——`return r`的缩进层级与堆栈中弹出的数字不匹配。）

### [2.1.9. 标记之间的空白](https://docs.python.org/3/reference/lexical_analysis.html#white-between-tokens)

Except at the beginning of a logical line or in string literals, the whitespace characters space, tab and formfeed can be used interchangeably to separate tokens. Whitespace is needed between two tokens only if their concatenation could otherwise be interpreted as a different token (e.g., ab is one token, but a b is two tokens).

## [2.2. 其他标记](https://docs.python.org/3/reference/lexical_analysis.html#other-tokens)

Besides NEWLINE, INDENT and DEDENT, the following categories of tokens exist: identifiers, keywords, literals, operators, and delimiters. Whitespace characters (other than line terminators, discussed earlier) are not tokens, but serve to delimit tokens. Where ambiguity exists, a token comprises the longest possible string that forms a legal token, when read from left to right.

## [2.3. 标识符和关键字](https://docs.python.org/3/reference/lexical_analysis.html#identifiers-and-keywords)

Identifiers (also referred to as names) are described by the following lexical definitions.

The syntax of identifiers in Python is based on the Unicode standard annex UAX-31, with elaboration and changes as defined below; see also PEP 3131 for further details.

Within the ASCII range (U+0001..U+007F), the valid characters for identifiers are the same as in Python 2.x: the uppercase and lowercase letters A through Z, the underscore _ and, except for the first character, the digits 0 through 9.

Python 3.0 introduces additional characters from outside the ASCII range (see PEP 3131). For these characters, the classification uses the version of the Unicode Character Database as included in the unicodedata module.

Identifiers are unlimited in length. Case is significant.

```python
identifier   ::=  xid_start xid_continue*
id_start     ::=  <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>
id_continue  ::=  <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>
xid_start    ::=  <all characters in id_start whose NFKC normalization is in "id_start xid_continue*">
xid_continue ::=  <all characters in id_continue whose NFKC normalization is in "id_continue*">
```

The Unicode category codes mentioned above stand for:

- Lu - uppercase letters
- Ll - lowercase letters
- Lt - titlecase letters
- Lm - modifier letters
- Lo - other letters
- Nl - letter numbers
- Mn - nonspacing marks
- Mc - spacing combining marks
- Nd - decimal numbers
- Pc - connector punctuations
- Other_ID_Start - explicit list of characters in PropList.txt to support backwards compatibility
- Other_ID_Continue - likewise

All identifiers are converted into the normal form NFKC while parsing; comparison of identifiers is based on NFKC.

A non-normative HTML file listing all valid identifier characters for Unicode 4.1 can be found at https://www.dcl.hpi.uni-potsdam.de/home/loewis/table-3131.html.

### [2.3.1. 关键字](https://docs.python.org/3/reference/lexical_analysis.html#keywords)

### [2.3.2. 保留类别的标识符](https://docs.python.org/3/reference/lexical_analysis.html#reserved-classes-of-identifiers)
